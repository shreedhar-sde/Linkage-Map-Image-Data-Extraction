{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install pytesseract\n",
        "!sudo apt install tesseract-ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4aQsCV_C46e",
        "outputId": "a9fcca39-e949-4527-9e1d-9fa994263a56"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.1.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 30 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 1s (3,582 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 126213 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UJ3VYSjSBuNw"
      },
      "outputs": [],
      "source": [
        "import unicodedata\n",
        "import re\n",
        "\n",
        "def segmentation(arr,odd_val):\n",
        "    en_ar=[]\n",
        "    for i in arr:\n",
        "        if i==odd_val:\n",
        "            en_ar.append(1)\n",
        "        else:\n",
        "            en_ar.append(0)\n",
        "    b=sum(en_ar)/len(en_ar)\n",
        "    k=0\n",
        "    l=0\n",
        "    p=0\n",
        "    i=0\n",
        "    reg=[]\n",
        "    while i < (len(en_ar)):\n",
        "        if en_ar[i]==1:\n",
        "            k=0\n",
        "            l=0\n",
        "            for j in range(i, len(en_ar)):\n",
        "                k+=en_ar[j]\n",
        "                l+=1\n",
        "                if (en_ar[j]==0 and k/l>b) or j==len(en_ar)-1:\n",
        "                    tmp=j-1 if j!=len(en_ar)-1 else j\n",
        "                    reg.append([i-int(2*b),tmp+int(2*b)])\n",
        "                    i=j\n",
        "                    break\n",
        "\n",
        "        i+=1\n",
        "    return reg\n",
        "\n",
        "def break_region(arr):\n",
        "    lp=[]\n",
        "    for i in range(len(arr)-1):\n",
        "        lp.append(arr[i+1][1]-arr[i][0])\n",
        "    return lp.index(max(lp))\n",
        "\n",
        "\n",
        "def remove_control_characters(s):\n",
        "    return \"\".join(ch for ch in s if unicodedata.category(ch) and unicodedata.category(ch)[0] != \"C\")\n",
        "\n",
        "def reject_outliers(_data, m = 2.8):\n",
        "    data=np.array(_data, dtype=np.float32)\n",
        "    d = np.abs(data - np.median(data))\n",
        "    mdev = np.median(d)\n",
        "    s = d/mdev if mdev else np.zeros(len(d))\n",
        "    return data[s<m]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def average(ar):\n",
        "  return sum(ar)/len(ar)\n",
        "\n",
        "def scale_decomposition(a,n_group):\n",
        "    n=len(a)\n",
        "    av=int(sum(a)/n)\n",
        "    rem_gs=[av]*(n_group*(int(n/n_group)+1)-n)\n",
        "    f_l=a+rem_gs\n",
        "    f_l.sort()\n",
        "    nw_s=len(f_l)/n_group\n",
        "    tmp=[]\n",
        "    g_l=[]\n",
        "    for i in range(len(f_l)):\n",
        "        tmp.append(f_l[i])\n",
        "        if (i+1)%nw_s==0:\n",
        "            g_l.append(tmp)\n",
        "            tmp=[]\n",
        "    g_l_f=[]\n",
        "    for i in g_l:\n",
        "      g_l_f.append(average(i))\n",
        "    return(g_l_f)\n",
        "\n",
        "def map_real_world_scale(a,v):\n",
        "    b=[]\n",
        "    c=[]\n",
        "    for i in a:\n",
        "        b.append(i-a[0])\n",
        "    f=b[-1]/v\n",
        "    for i in b:\n",
        "        c.append(round((float(i/f)),2))\n",
        "    return c\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def vertical_scale_cordinate(img):\n",
        "\n",
        "  gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "  blurred_img = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "  edges = cv2.Canny(blurred_img,50,500,apertureSize = 3)\n",
        "  minLineLength = 100\n",
        "  maxLineGap = 0.4\n",
        "  lines = cv2.HoughLinesP(edges,1,np.pi/90,200,minLineLength,maxLineGap)\n",
        "  ver=[]\n",
        "  for line in lines:\n",
        "      x1,y1,x2,y2=line[0]\n",
        "      if x1-x2==0:\n",
        "        ver.append(x1)\n",
        "        cv2.line(img,(x1,y1),(x2,y2),(0,255,0),1)\n",
        "  return(max(ver))\n",
        "\n",
        "\n",
        "def horizantal_scale_cordinate(img,ver):\n",
        "\n",
        "  gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "  blurred_img = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "  edges = cv2.Canny(blurred_img,50,500,apertureSize = 3)\n",
        "  minLineLength = 100\n",
        "  maxLineGap = 0\n",
        "  lines = cv2.HoughLinesP(edges,1,np.pi/90,40,minLineLength,maxLineGap)\n",
        "  hr=[]\n",
        "  for line in lines:\n",
        "      x1,y1,x2,y2=line[0]\n",
        "      cv2.line(img,(x1,y1),(x2,y2),(0,255,0),1)\n",
        "      if x1==x2:\n",
        "        continue\n",
        "      sl=float(y2-y1)/float(x1-x2)\n",
        "      c=-float(y1)-float(sl*x1)\n",
        "      hor=sl*ver+c\n",
        "      hr.append(float(-hor))\n",
        "\n",
        "  return hr"
      ],
      "metadata": {
        "id": "GAq-nKeyB_07"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def find_and_mark_regions(image_path):\n",
        "  img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "  blurred_img = cv2.GaussianBlur(img, (5, 5), 0)\n",
        "  binary_img = cv2.adaptiveThreshold(\n",
        "    blurred_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
        ")\n",
        "\n",
        "# Optional: Dilation/erosion\n",
        "  kernel = np.ones((1, 1), np.uint8)\n",
        "  binary_img = cv2.dilate(binary_img, kernel, iterations=1)\n",
        "\n",
        "\n",
        "\n",
        "  sample_rows=[2,3,4,6,7]\n",
        "  scale=[]\n",
        "  markers=[]\n",
        "  for i in sample_rows:\n",
        "    mid_y=int(binary_img.shape[0]/i)\n",
        "    region=segmentation(binary_img[mid_y],0)\n",
        "    brk=break_region(region)\n",
        "    scale.append(region[brk][1])\n",
        "    markers.append(region[brk+1][0])\n",
        "\n",
        "  row=binary_img.shape[0]\n",
        "  col=binary_img.shape[1]\n",
        "  m2=max(scale)+int(max(scale)/8)\n",
        "  m3=min(markers) -int(max(markers)/10)\n",
        "\n",
        "\n",
        "  cv2.imwrite(\"/content/scale_image.jpg\", binary_img[:,0:m2])\n",
        "  cv2.imwrite(\"/content/marker_image.jpg\", binary_img[:,m3:col])\n",
        "  cv2.imwrite(\"/content/horizontal_markup.jpg\", binary_img[:,m3:m2])\n",
        "  return(binary_img[:,0:m2],binary_img[:,m3:col])\n",
        "\n",
        "\n",
        "\n",
        "image_file = \"/content/lm 9.jpg\"  # Replace with the actual image path.\n",
        "\n",
        "bi_s,bi_m=find_and_mark_regions(image_file)\n",
        "\n"
      ],
      "metadata": {
        "id": "kaxwrxOgCDnA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "pytesseract.pytesseract.tesseract_cmd = (\n",
        "    r'/usr/bin/tesseract'\n",
        ")\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "extracted_text = pytesseract.image_to_string(bi_m)\n",
        "data = pytesseract.image_to_data(bi_s, output_type=pytesseract.Output.DICT, config='--psm 11')\n",
        "text_data = []\n",
        "for i in range(len(data['text'])):\n",
        "    if re.sub('[^0-9|^\\.]','', data['text'][i]):  # Check for non-empty text\n",
        "        text_data.append({\n",
        "            'text': re.sub('[^0-9|^\\.]','', data['text'][i]),\n",
        "            'top': data['top'][i]  # Y-coordinate of the bounding box\n",
        "        })\n",
        "\n",
        "sorted_text = sorted(text_data, key=lambda x: x['top'])\n",
        "final_text = '\\n'.join([item['text'] for item in sorted_text])\n",
        "final_numbers=[]\n",
        "for j in final_text.split(\"\\n\"):\n",
        "  final_numbers.append(float(j))\n",
        "\n",
        "final_numbers.sort()\n",
        "\n",
        "\n",
        "cleaned_extract = [remove_control_characters(item) for item in extracted_text.split(\"\\n\")]\n",
        "cleaned_extract_f=[]\n",
        "for i in cleaned_extract:\n",
        "  if i.replace(' ',''):\n",
        "    cleaned_extract_f.append(i)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "img=cv2.imread(\"/content/horizontal_markup.jpg\")\n",
        "scale_col=float(vertical_scale_cordinate(img))\n",
        "scale_hor=(horizantal_scale_cordinate(img,scale_col))\n",
        "scale_hor_f=scale_decomposition(scale_hor,len(cleaned_extract_f))\n",
        "final_numbers=reject_outliers(final_numbers)\n",
        "scale_map=map_real_world_scale(scale_hor_f,float(final_numbers[-1])) #final_numbers[-1]\n",
        "final_dict=dict(zip(cleaned_extract_f,scale_map))\n",
        "img_o2 = cv2.imread(image_file, cv2.IMREAD_COLOR)\n",
        "\n",
        "for i in final_dict.keys():\n",
        "  print(i,final_dict[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weafRkynCFed",
        "outputId": "bfc68509-5771-4300-91ae-ffb624d513a6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bulge 0.0\n",
            "Crocs 40.63\n",
            "Paste, Crop 50.81\n",
            "Stub 65.52\n",
            "Plus 75.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z7dP_nxsDCiy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}